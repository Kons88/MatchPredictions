library(randomForest)
library(e1071)
library(nnet)
library(rvest)

# Assuming you have already trained additional models such as Random Forest, Naive Bayes, and Neural Networks

# Specify the URL
url <- "https://www.tostoixima.gr/live/soccer/2024-05-21"

# Read the HTML content from the URL
page <- read_html(url)

# Extract the table(s) using CSS selectors
tables <- page %>% html_nodes("table")

# If there are multiple tables, you might need to specify which one you want
# For example, tables[[1]] for the first table

# Convert the table to a data frame
data <- tables %>% html_table()

mydat <- as.data.frame(data[[1]][,c(3,4,6,8,12)])

# Convert first four columns to numeric
mydat[, 1:4] <- apply(mydat[, 1:4], 2, as.numeric)

# Identify rows with non-numeric values in the first four columns
non_numeric_rows <- apply(mydat[, 1:4], 1, function(x) any(is.na(x)))

# Subset dataframe to keep only rows with all numeric values in the first four columns
df_clean <- mydat[!non_numeric_rows, ]

# Change Column names
colnames(df_clean) <- c("Code", "Home", "Draw", "Away", "Result")
colnames(all_data) <- c("Code", "Home", "Draw", "Away", "Result")
df_clean$Result <- NULL

# Assuming you have already trained and tested your base models
multinom_model <- multinom(Result ~ ., data = all_data)
rf_model <- randomForest(factor(Result) ~ ., data = all_data[,-1])
nb_model <- naiveBayes(as.factor(Result) ~ ., data = all_data[,-1])
nn_model <- nnet::multinom(Result ~ ., data = all_data[,-1], MaxNWts = 10000)
svm_model <- svm(as.factor(Result) ~ ., data = all_data[,-1], kernel = "radial")

# Combine predictions from base models into a data frame
multinomial_prediction = predict(multinom_model, newdata = df_clean, type = "class")
# Add predictions from additional models (Random Forest, Naive Bayes, Neural Networks)
# Example:
RF_prediction = predict(rf_model, newdata = df_clean[,-1], type = "class")
NB_prediction = predict(nb_model, newdata = df_clean[,-1], type = "class")
NN_prediction = predict(nn_model, newdata = df_clean[,-1], type = "class")
SVM_prediction <- predict(svm_model, newdata = df_clean[,-1], type = "class")
base_model_predictions <- data.frame(multinomial_prediction, RF_prediction, NB_prediction, NN_prediction)

# Train the meta-model (multinomial logistic regression)
meta_model <- multinom(multinomial_prediction ~ ., data = base_model_predictions)

# Make predictions using the meta-model
meta_model_predictions <- predict(meta_model, newdata = base_model_predictions, type = "class")

# Combine predictions with original data
df_clean$Meta_Prediction <- meta_model_predictions

# Print the dataframe with meta-model predictions
print(df_clean)

# Filter rows where the meta-model predicts "X"
df_clean[df_clean$Meta_Prediction == "X", ]

# Aggregated result
aggregated.result <- df_clean[(NB_prediction==NN_prediction)&(multinomial_prediction==RF_prediction)&(NN_prediction==multinomial_prediction)&(NB_prediction==multinomial_prediction)&(NN_prediction==RF_prediction)&(NB_prediction==RF_prediction),]
aggregated.result

# Full prediction results
full.pred <- data.frame(Code=df_clean[,1],NB=NB_prediction,NN=NN_prediction,RF=RF_prediction, Multi=multinomial_prediction, SVM=SVM_prediction)